<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" />
<title>ImpMIA · Membership Inference via Implicit Bias & KKT</title>

<meta name="description" content="Project page for ImpMIA: a white-box membership inference attack that leverages neural networks’ implicit bias and KKT conditions." />
  <link rel="canonical" href="https://yuvalgol123.github.io/ImpMIA/" />
  <meta property="og:type" content="website" />
  <meta property="og:title" content="ImpMIA — Membership Inference via Implicit Bias & KKT" />
  <meta property="og:description" content="ImpMIA: a white-box membership inference attack leveraging implicit bias and KKT." />
  <meta property="og:url" content="https://yuvalgol123.github.io/ImpMIA/" />
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="ImpMIA — Membership Inference via Implicit Bias & KKT" />
  <meta name="twitter:description" content="ImpMIA: a white-box membership inference attack leveraging implicit bias and KKT." />
  <meta property="og:site_name" content="ImpMIA" />
  <meta property="og:locale" content="en_US" />
  <meta name="theme-color" content="#0f172a" />
  <meta name="robots" content="index,follow" />

  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&family=Roboto+Mono:wght@400;600&display=swap" rel="stylesheet" />
  <link rel="icon" href="buttons/web_logo3.png" />

<style>
    html { font-size: 112%; }
    @media (max-width: 768px){
      html { font-size: 102%; } 
    }
  :root{
    --bg:#0b0c10; --surface:#111318; --text:#e8eaed; --muted:#aab2bf;
    --brand:#5dd3ff; --brand2:#7ef7d6; --ring:rgba(125,211,252,.45);
    --max: 1100px;
  }
  @media (prefers-color-scheme: light){
    :root{
      --bg:#f7f7f8; --surface:#ffffff; --text:#1a1c1f; --muted:#525b65;
      --brand:#0077ff; --brand2:#00c9a7; --ring:rgba(0,119,255,.22);
    }
  }

  *{ box-sizing:border-box }
  html,body{ height:100% }
  body{
    margin:0;
    font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, "Helvetica Neue", Arial, "Noto Sans";
    color:var(--text); background:var(--bg); line-height:1.65;
    -webkit-font-smoothing:antialiased; text-rendering:optimizeLegibility;
  }

  .hero{
    max-width:var(--max); margin:32px auto 0; padding:0 16px; text-align:center;
  }
  .title{
    font-size: clamp(26px, 4.6vw, 44px); line-height:1.08; margin:6px 0 8px; font-weight:800;
    background:linear-gradient(90deg, var(--text), color-mix(in oklab, var(--text) 70%, var(--brand)));
    -webkit-background-clip:text; background-clip:text; color:transparent;
  }
  .authors{ margin:8px 0 4px; font-weight:600 }
  .authors a{ color:inherit; text-decoration:none }
  .authors a:hover{ text-decoration:underline }
  .affil{ color:var(--muted); margin:0 }
  .cta{ display:flex; gap:10px; justify-content:center; margin:14px 0 6px; flex-wrap:wrap }
  .btn{
    text-decoration:none; font-weight:700; color:#061016; padding:10px 14px; border-radius:10px;
    background:linear-gradient(90deg, var(--brand), var(--brand2)); box-shadow:0 8px 24px -10px var(--ring);
  }
  .btn.secondary{ background:transparent; color:var(--text); border:1px solid color-mix(in oklab, var(--text) 18%, transparent) }

  section{
    max-width:var(--max); margin:22px auto; padding:0 16px;
  }
  .card{
    background:var(--surface);
    border:1px solid color-mix(in oklab, var(--text) 10%, transparent);
    border-radius:16px; padding:18px 16px; box-shadow:0 14px 30px -24px var(--ring);
  }
  h2.section-title{
    font-size: clamp(20px, 3vw, 28px); margin:2px 0 12px; font-weight:800;
  }

  figure{ margin:0 }
  .img{
    width:100%;
    height:auto;
    display:block;
    border-radius:12px;
    border:1px solid color-mix(in oklab, var(--text) 10%, transparent);
  }
  @media (prefers-color-scheme: dark){
    .img-well{ background:#ffffff; padding:8px; border-radius:14px; }
    .img-well > img{ border-radius:8px; border:none }
  }
  @media (prefers-color-scheme: light){
    .img-well{ padding:0; background:transparent }
  }

  p, ul{ margin:14px 0 0 }
  ul{ padding-left:20px }
  .mono, code{ font-family:"Roboto Mono", ui-monospace, SFMono-Regular, Menlo, Consolas, monospace }

  .bibtex{ white-space:pre; overflow-x:auto; background:#0e1116; color:#dfe5ee;
    padding:12px; border-radius:12px; border:1px solid color-mix(in oklab, var(--text) 12%, transparent) }
</style>
</head>

<body>

<header class="hero">
  <h1 class="title">ImpMIA: Leveraging Implicit Bias for Membership Inference under Realistic Scenarios</h1>

  <p class="authors">
    <a href="mailto:yuval.golbari@weizmann.ac.il">Yuval Golbari</a><sup>*</sup> ·
    <a href="mailto:navve.wasserman@weizmann.ac.il">Navve Wasserman</a><sup>*</sup> ·
    <a href="mailto:gal.vardi@weizmann.ac.il">Gal Vardi</a> ·
    <a href="mailto:michal.irani@weizmann.ac.il">Michal Irani</a>
  </p>
  <p class="auth-note">* Equal contribution</p>

  <p class="affil">Weizmann Institute of Science</p>
  <div class="cta">
    <a class="btn" href="https://arxiv.org/abs/2510.10625" target="_blank" rel="noopener">Read on arXiv</a>
    <a class="btn secondary" href="#" aria-disabled="true" role="button"> Code &amp; Datasets <span class="badge">coming soon</span>
</a>  </div>
</header>


  <section class="card" id="abstract">
    <h2 class="section-title">Abstract</h2>
    <figure class="img-well">
    </figure>
<p>
  Determining which data samples were used to train a model&mdash;known as
  <em>Membership Inference Attack (MIA)</em>&mdash;is a well-studied and important
  problem with implications for data privacy. Black-box methods presume access only
  to the model’s outputs and often rely on training auxiliary reference models.
  While they show strong empirical performance, they depend on assumptions that
  rarely hold in real-world settings: (i) the attacker knows the training
  hyperparameters; (ii) all available non-training samples come from the same
  distribution as the training data; and (iii) the fraction of training data in the
  evaluation set is known. In this work, we demonstrate that removing these
  assumptions leads to a significant drop in black-box performance. We introduce
  <strong>ImpMIA</strong>, a membership inference attack that exploits the
  <strong>implicit bias</strong> of neural networks, removing the need for any
  reference models and their assumptions. <strong>ImpMIA is a white-box attack</strong>
  &ndash; a setting that assumes access to model weights and is increasingly
  realistic given many publicly available models (e.g., via Hugging Face). Building
  on maximum-margin implicit-bias theory, ImpMIA uses the
  <strong>Karush&ndash;Kuhn&ndash;Tucker (KKT)</strong> optimality conditions to
  identify training samples by finding those whose gradients most strongly
  reconstruct the trained model’s parameters. As a result, ImpMIA achieves
  state-of-the-art performance compared to both black- and white-box attacks in
  realistic settings where only the model weights and a superset of the training
  data are available.
</p>
  </section>

  <!-- KKT -->
<section class="card" id="kkt">
  <h2 class="section-title">Setting, Implicit Bias &amp; KKT</h2>
  <figure class="img-well">
    <img class="img" src="figures/teaser1.png" alt="Setting and KKT formulation">
  </figure>
  <p>
    <strong>Setting.</strong> We assume <em>white-box</em> access to a trained model’s parameters
    <span class="mono">θ</span> (and the ability to compute gradients w.r.t. <span class="mono">θ</span>), and an
    <em>inference superset</em> <span class="mono">S</span> that contains the unknown training set
    <span class="mono">T ⊆ S</span>. The objective is to determine, for each candidate
    <span class="mono">x ∈ S</span>, whether it belongs to the original training set.
  </p>
  <p>
    <strong>Implicit Bias → KKT.</strong> Gradient-based training is biased toward
    <em>max-margin</em> solutions. At such stationary points, the Karush–Kuhn–Tucker (KKT) conditions imply that the
    parameters align with a non-negative combination of per-sample margin gradients:
    <span class="mono">θ ≈ Σᵢ λᵢ gᵢ(xᵢ; θ)</span> with <span class="mono">λᵢ ≥ 0</span>.
    Here <span class="mono">gᵢ</span> denotes the gradient of a margin-based objective at sample
    <span class="mono">xᵢ</span>. Only a small set of influential (“support”) samples receive non-zero multipliers,
    typically those closest to the decision boundary (by complementary slackness).
  </p>
</section>
<!-- ATTACK -->
<section class="card" id="attack">
  <h2 class="section-title">ImpMIA Attack (λ-Optimization)</h2>
  <figure class="img-well">
    <img class="img" src="figures/teaser2.png" alt="Lambda optimization overview">
  </figure>
<p>
  We exploit the KKT link that the trained weights can be written as a non-negative mix of per-sample margin gradients:
  <span class="mono">θ = Σ<sub>i∈X_train</sub> λᵢ gᵢ</span>, <span class="mono">λᵢ ≥ 0</span>. Given only a superset
  <span class="mono">X<sub>sup</sub></span>, we compute multiclass margin gradients
  <span class="mono">gᵢ = ∇<sub>θ</sub>[Φ<sub>yᵢ</sub>(θ;xᵢ) − max<sub>j≠yᵢ</sub> Φ<sub>j</sub>(θ;xᵢ)]</span>,
  stack them as <span class="mono">A = [g₁|…|g_M] ∈ ℝ^{p×M}</span>, and solve
  <span class="mono">Aλ = θ</span> (with <span class="mono">λ ≥ 0</span>) to obtain one coefficient per candidate.
  Large <span class="mono">λᵢ</span> ⇒ higher membership likelihood (especially near-margin points); if
  <span class="mono">|X<sub>sup</sub>| ≤ p</span> and columns of <span class="mono">A</span> are independent, the solution is unique.
</p>
<ul>
  <li><strong>Filters & aug:</strong> drop misclassified samples; add a horizontal flip.</li>
  <li><strong>Blockwise solve:</strong> split parameters into ~<span class="mono">1.5×10⁵</span>-dim blocks; solve per block to reduce memory/conditioning issues.</li>
  <li><strong>Stabilization:</strong> center/normalize each block of <span class="mono">A</span> and the matching slice of <span class="mono">θ</span>.</li>
  <li><strong>Aggregation:</strong> aggregate coefficients across blocks/augs to form the final score and suppress spurious non-member spikes.</li>
</ul>
</section>

  <!-- EVIDENCE -->
  <section class="card" id="evidence">
    <h2 class="section-title">λ Score vs. Distance from Decision Boundary</h2>
    <figure class="img-well">
      <img class="img" src="figures/lambda_vs_distance.png" alt="Lambda score vs. decision-boundary distance">
    </figure>
    <p>
      <strong>Results of ImpMIA.</strong> Members receive consistently higher λ scores—even at similar margin distances—while non-members concentrate near λ≈0. Scatter plot of superset samples: x-axis = distance from the decision boundary, y-axis = λ score; points are colored by membership (member vs. non-member). High λ strongly indicates membership.
    </p>
  </section>

  <!-- RESULTS -->
  <section class="card" id="results">
    <h2 class="section-title">Results: No Assumptions Setting</h2>
    <figure class="img-well">
      <img class="img" src="figures/table_main.png" alt="Membership inference results across datasets">
    </figure>
    <p>
      <strong>Evaluation protocol (no-assumptions).</strong> We audit on CIFAR-10/100 and CINIC-10 with white-box access to the released weights (gradients computed on-the-fly). The primary metric is <strong>TPR at low FPR</strong>; AUC is reported for context. We remove the assumptions commonly used by reference-model MIAs:
    </p>
    <ul>
      <li><strong>Unknown training configuration.</strong> The attacker does not know the target’s hyperparameters. For methods that require reference models, we train them under <em>mismatched</em> settings (optimizer schedule/scale, batch size, regularization, training length) instead of the target’s true config.</li>

      <li><strong>Different data distribution.</strong> The candidate pool intentionally mixes in-distribution (ID) and out-of-distribution (OOD) samples (e.g., CINIC-10 / OpenImages variants), so non-members are not drawn from the same distribution as the target’s training data.</li>

      <li><strong>Unknown fraction of members.</strong> The attacker does not know the member ratio in the candidate pool. Reference-based methods that assume a fixed ratio must calibrate on a mismatched mixture.</li>

      <li><strong>Removing all assumptions.</strong> We combine the above: mixed ID/OOD pool, mismatched reference-model training, and hidden member ratio.</li>
    </ul>
    <p>
      <strong>Outcome.</strong> Under these realistic settings, reference-model attacks degrade sharply, while <strong>ImpMIA</strong> maintains strong detection at tiny FPRs. See the table for per-dataset trends.
    </p>


  </section>

  <!-- ASSUMPTIONS -->
  <section class="card" id="assumptions">
    <h2 class="section-title">Evaluation of Assumptions Influence</h2>
    <figure class="img-well">
      <img class="img" src="figures/table_assumptions.png" alt="Influence of assumptions on membership inference">
    </figure>
    <p>
      Ablation on CINIC-10 removing: known training config, matched non-member distribution, and known member ratio. TPR (%) at FPR = 0.01% / 0.00%.
      Black-box attacks collapse as assumptions are removed; <strong>ImpMIA</strong> remains strong and often improves.
    </p>
  </section>

<!-- CURVE -->
<section class="card" id="curve">
  <style>
    #curve .wrap{
      display:grid; gap:18px; align-items:center;
      grid-template-columns: 1.05fr .95fr;
    }
    #curve figure{ margin:0; }
    #curve .plot{ justify-self:end; max-width:640px; width:100%; }
    @media (max-width: 980px){
      #curve .wrap{ grid-template-columns:1fr; }
      #curve .plot{ justify-self:stretch; }
    }
  </style>

  <div class="wrap">
    <div class="text">
      <h2 class="section-title">Effect of Assumption Removal</h2>
    <p>
      The curve shows the reliance of reference-model attacks on these assumptions: as each assumption is removed, their performance drops at a fixed zero-FPR operating point, while <strong>ImpMIA</strong> remains comparatively stable—highlighting its assumption-agnostic design.
    </p>
    </div>

    <figure class="img-well plot">
      <img class="img" src="figures/assumption_removal_curve.png"
           alt="Effect of assumption removal on TPR at 0% FPR">
    </figure>
  </div>
</section>

  <!-- BIBTEX -->
  <section class="card" id="bibtex">
    <h2 class="section-title">BibTeX</h2>
    <figure></figure>
    <div class="bibtex">
@article{golbari2025impMIA,
  title   = {ImpMIA: Leveraging Implicit Bias for Membership Inference under Realistic Scenarios},
  author  = {Golbari, Yuval and Wasserman, Navve and Vardi, Gal and Irani, Michal},
  journal = {arXiv preprint arXiv:2510.10625},
  year    = {2025}
}
    </div>
  </section>

  <section style="max-width:var(--max); margin:24px auto 40px; padding:0 16px; color:var(--muted); text-align:center;">
    © 2025 ImpMIA Authors.
  </section>

</body>
</html>
