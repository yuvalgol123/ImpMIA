<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" />
<title>ImpMIA · Membership Inference via Implicit Bias & KKT</title>

<meta name="description" content="Project page for ImpMIA: a white-box membership inference attack that leverages neural networks’ implicit bias and KKT conditions." />
  <link rel="canonical" href="https://yuvalgol123.github.io/ImpMIA/" />
  <meta property="og:type" content="website" />
  <meta property="og:title" content="ImpMIA — Membership Inference via Implicit Bias & KKT" />
  <meta property="og:description" content="ImpMIA: a white-box membership inference attack leveraging implicit bias and KKT." />
  <meta property="og:url" content="https://yuvalgol123.github.io/ImpMIA/" />
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="ImpMIA — Membership Inference via Implicit Bias & KKT" />
  <meta name="twitter:description" content="ImpMIA: a white-box membership inference attack leveraging implicit bias and KKT." />
  <meta property="og:site_name" content="ImpMIA" />
  <meta property="og:locale" content="en_US" />
  <meta name="theme-color" content="#0f172a" />
  <meta name="robots" content="index,follow" />

  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&family=Roboto+Mono:wght@400;600&display=swap" rel="stylesheet" />
  <link rel="icon" href="buttons/web_logo3.png" />

<style>
    html { font-size: 112%; }
    @media (max-width: 768px){
      html { font-size: 102%; } 
    }
  :root{
    --bg:#0b0c10; --surface:#111318; --text:#e8eaed; --muted:#aab2bf;
    --brand:#5dd3ff; --brand2:#7ef7d6; --ring:rgba(125,211,252,.45);
    --max: 1100px;
  }
  @media (prefers-color-scheme: light){
    :root{
      --bg:#f7f7f8; --surface:#ffffff; --text:#1a1c1f; --muted:#525b65;
      --brand:#0077ff; --brand2:#00c9a7; --ring:rgba(0,119,255,.22);
    }
  }

  *{ box-sizing:border-box }
  html,body{ height:100% }
  body{
    margin:0;
    font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, "Helvetica Neue", Arial, "Noto Sans";
    color:var(--text); background:var(--bg); line-height:1.65;
    -webkit-font-smoothing:antialiased; text-rendering:optimizeLegibility;
  }

  .hero{
    max-width:var(--max); margin:32px auto 0; padding:0 16px; text-align:center;
  }
  .title{
    font-size: clamp(26px, 4.6vw, 44px); line-height:1.08; margin:6px 0 8px; font-weight:800;
    background:linear-gradient(90deg, var(--text), color-mix(in oklab, var(--text) 70%, var(--brand)));
    -webkit-background-clip:text; background-clip:text; color:transparent;
  }
  .authors{ margin:8px 0 4px; font-weight:600 }
  .authors a{ color:inherit; text-decoration:none }
  .authors a:hover{ text-decoration:underline }
  .affil{ color:var(--muted); margin:0 }
  .cta{ display:flex; gap:10px; justify-content:center; margin:14px 0 6px; flex-wrap:wrap }
  .btn{
    text-decoration:none; font-weight:700; color:#061016; padding:10px 14px; border-radius:10px;
    background:linear-gradient(90deg, var(--brand), var(--brand2)); box-shadow:0 8px 24px -10px var(--ring);
  }
  .btn.secondary{ background:transparent; color:var(--text); border:1px solid color-mix(in oklab, var(--text) 18%, transparent) }

  section{
    max-width:var(--max); margin:22px auto; padding:0 16px;
  }
  .card{
    background:var(--surface);
    border:1px solid color-mix(in oklab, var(--text) 10%, transparent);
    border-radius:16px; padding:18px 16px; box-shadow:0 14px 30px -24px var(--ring);
  }
  h2.section-title{
    font-size: clamp(20px, 3vw, 28px); margin:2px 0 12px; font-weight:800;
  }

  figure{ margin:0 }
  .img{
    width:100%;
    height:auto;
    display:block;
    border-radius:12px;
    border:1px solid color-mix(in oklab, var(--text) 10%, transparent);
  }
  @media (prefers-color-scheme: dark){
    .img-well{ background:#ffffff; padding:8px; border-radius:14px; }
    .img-well > img{ border-radius:8px; border:none }
  }
  @media (prefers-color-scheme: light){
    .img-well{ padding:0; background:transparent }
  }

  p, ul{ margin:14px 0 0 }
  ul{ padding-left:20px }
  .mono, code{ font-family:"Roboto Mono", ui-monospace, SFMono-Regular, Menlo, Consolas, monospace }

  .bibtex{ white-space:pre; overflow-x:auto; background:#0e1116; color:#dfe5ee;
    padding:12px; border-radius:12px; border:1px solid color-mix(in oklab, var(--text) 12%, transparent) }
</style>
</head>

<body>

<header class="hero">
  <h1 class="title">ImpMIA: Leveraging Implicit Bias for Membership Inference under Realistic Scenarios</h1>

  <p class="authors">
    <a href="mailto:yuval.golbari@weizmann.ac.il">Yuval Golbari</a><sup>*</sup> ·
    <a href="mailto:navve.wasserman@weizmann.ac.il">Navve Wasserman</a><sup>*</sup> ·
    <a href="mailto:gal.vardi@weizmann.ac.il">Gal Vardi</a> ·
    <a href="mailto:michal.irani@weizmann.ac.il">Michal Irani</a>
  </p>
  <p class="auth-note">* Equal contribution</p>

  <p class="affil">Weizmann Institute of Science</p>
  <div class="cta">
    <a class="btn" href="https://arxiv.org/abs/2510.10625" target="_blank" rel="noopener">Read on arXiv</a>
    <a class="btn secondary" href="#" aria-disabled="true" role="button"> Code &amp; Datasets <span class="badge">coming soon</span>
</a>  </div>
</header>


  <section class="card" id="abstract">
    <h2 class="section-title">Abstract</h2>
    <figure class="img-well">
    </figure>
<p>
  Determining which data samples were used to train a model&mdash;known as
  <em>Membership Inference Attack (MIA)</em>&mdash;is a well-studied and important
  problem with implications for data privacy. Black-box methods presume access only
  to the model’s outputs and often rely on training auxiliary reference models.
  While they show strong empirical performance, they depend on assumptions that
  rarely hold in real-world settings: (i) the attacker knows the training
  hyperparameters; (ii) all available non-training samples come from the same
  distribution as the training data; and (iii) the fraction of training data in the
  evaluation set is known. In this work, we demonstrate that removing these
  assumptions leads to a significant drop in black-box performance. We introduce
  <strong>ImpMIA</strong>, a membership inference attack that exploits the
  <strong>implicit bias</strong> of neural networks, removing the need for any
  reference models and their assumptions. <strong>ImpMIA is a white-box attack</strong>
  &ndash; a setting that assumes access to model weights and is increasingly
  realistic given many publicly available models (e.g., via Hugging Face). Building
  on maximum-margin implicit-bias theory, ImpMIA uses the
  <strong>Karush&ndash;Kuhn&ndash;Tucker (KKT)</strong> optimality conditions to
  identify training samples by finding those whose gradients most strongly
  reconstruct the trained model’s parameters. As a result, ImpMIA achieves
  state-of-the-art performance compared to both black- and white-box attacks in
  realistic settings where only the model weights and a superset of the training
  data are available.
</p>
  </section>

  <!-- KKT -->
<section class="card" id="kkt">
  <h2 class="section-title">Setting, Implicit Bias &amp; KKT</h2>
  <figure class="img-well">
    <img class="img" src="figures/teaser1.png" alt="Setting and KKT formulation">
  </figure>
  <p>
    <strong>Setting.</strong> We assume <em>white-box</em> access to a trained model’s parameters
    <span class="mono">θ</span> (and the ability to compute gradients w.r.t. <span class="mono">θ</span>), and an
    <em>inference superset</em> <span class="mono">S</span> that contains the unknown training set
    <span class="mono">T ⊆ S</span>. The objective is to determine, for each candidate
    <span class="mono">x ∈ S</span>, whether it belongs to the original training set.
  </p>
  <p>
    <strong>Implicit Bias → KKT.</strong> Gradient-based
    optimization tends to converge to solutions that satisfy the Karush–Kuhn–Tucker (KKT) optimality
    conditions of a certain maximum-margin problem.  In practice, this implies that the trained parameters of a network can be approximately expressed as a
    linear combination of per-sample gradients from the training set: <br> <span class="mono">θ ≈ Σᵢ λᵢ gᵢ(xᵢ; θ)</span>, where <em>each coefficient λᵢ is nonnegative</em> and <span class="mono">gᵢ</span> is the per-sample margin gradient for example <span class="mono">xᵢ</span>.
  </p>
</section>
<!-- ATTACK -->
<section class="card" id="attack">
  <h2 class="section-title">ImpMIA Attack (λ-Optimization)</h2>
  <figure class="img-well">
    <img class="img" src="figures/teaser2.png" alt="Lambda optimization overview">
  </figure>
<p>
  Given a set of candidate samples and the trained network weights, we optimize a set of coefficients
  <span class="mono">{λᵢ}</span>—one for each sample—that best reconstruct the network parameters
  <span class="mono">θ</span>. This provides the key signal: training samples are expected to receive
  significantly larger coefficients, while non-members remain small.
</p>
</section>

  <!-- EVIDENCE -->
  <section class="card" id="evidence">
    <h2 class="section-title">Distinguishing Members vs. Non-Members</h2>
    <figure class="img-well">
      <img class="img" src="figures/lambda_vs_distance.png" alt="Lambda score vs. decision-boundary distance">
    </figure>
    <p>
      Scatter over the superset:
      x-axis = distance to the decision boundary; y-axis = λ score; points colored by membership.
      Members receive consistently higher λ while non-members cluster near λ&nbsp;&approx;&nbsp;0.
    </p>
  </section>

  <!-- RESULTS -->
<section class="card" id="results">
  <h2 class="section-title">Quantitative Results Under Realistic Settings (No Assumptions)</h2>
  <figure class="img-well">
    <img class="img" src="figures/table_main.png" alt="Membership inference results across datasets">
  </figure>

  <p>
    We compare <strong>ImpMIA</strong> against state-of-the-art <em>black-box</em> and <em>white-box</em> membership attacks across three commonly used datasets—CIFAR-10, CIFAR-100, and CINIC-10. We audit with white-box access to released weights. The primary metric is
    <strong>TPR at ultra-low FPR</strong> (e.g., 0.01% / 0.00%); AUC is reported for context. We remove assumptions commonly
    used by reference-model MIAs—<em>known training configuration</em>, <em>matched non-member distribution</em>, and
    <em>known member ratio</em>—and also report the combined <em>no-assumptions</em> case.
  </p>
  <p>
    <strong>Outcome.</strong> Under these realistic settings, reference-model attacks degrade sharply, while
    <strong>ImpMIA</strong> maintains strong detection at tiny FPRs. See the table for per-dataset trends.
  </p>
</section>

<!-- ASSUMPTIONS -->
<section class="card" id="assumptions">
  <h2 class="section-title">Influence of Assumptions (Ablation)</h2>
  <figure class="img-well">
    <img class="img" src="figures/table_assumptions.png" alt="Ablation of assumptions and their effect on membership inference performance">
  </figure>

  <p>
    We quantify how common assumptions used by reference-model MIAs affect results.
    The table reports TPR (%) at ultra-low FPR (0.01% / 0.00%) on CINIC-10 while
    removing each assumption.
  </p>

  <ul>
    <li><strong>Unknown training configuration.</strong> The attacker does not know the target’s hyperparameters.</li>

    <li><strong>Different data distribution.</strong> The candidate pool mixes ID and OOD samples; <em>all members are ID</em>, while OOD samples appear only as non-members.</li>


    <li><strong>Unknown fraction of members.</strong> The attacker does not know the member ratio in the
      candidate pool.</li>

    <li><strong>All assumptions removed.</strong> Combine the above: mixed ID/OOD pool, mismatched
      reference-model training, and hidden member ratio.</li>
  </ul>

  <p><strong>Outcome.</strong> As assumptions are removed, reference-model attacks degrade sharply—especially at
    zero-FPR operating points—while <strong>ImpMIA</strong> remains stable and often improves, retaining strong
    detection at tiny FPR without tuning for the member ratio or the exact training configuration.</p>
</section>

<!-- CURVE -->
<section class="card" id="curve">
  <style>
    #curve .wrap{
      display:grid; gap:18px; align-items:center;
      grid-template-columns: 1.05fr .95fr;
    }
    #curve figure{ margin:0; }
    #curve .plot{ justify-self:end; max-width:640px; width:100%; }
    #curve .text, #curve .text * { font-style: normal; font-family: inherit; }
    @media (max-width: 980px){
      #curve .wrap{ grid-template-columns:1fr; }
      #curve .plot{ justify-self:stretch; }
    }
  </style>

  <div class="wrap">
    <div class="text">
      <h2 class="section-title">Effect of Assumption Removal</h2>
      <p>
        Performance of the best prior method (LiRA) and our method (ImpMIA) under the progressive removal of assumptions on CINIC-10.
      </p>
      <p>
        Y-axis: TPR at 0% FPR. X-axis: assumptions removed in sequence — Known training configuration → Matched non-member distribution → Known member ratio → All removed.
      </p>
      <p>
        As assumptions are removed, LiRA performance drops sharply, while <strong>ImpMIA</strong> remains stable, showing minimal dependence on these assumptions.
      </p>
    </div>

    <figure class="img-well plot">
      <img class="img" src="figures/assumption_removal_curve.png"
           alt="CINIC-10: Performance of LiRA and ImpMIA under progressive assumption removal">
    </figure>
  </div>
</section>


  <!-- BIBTEX -->
  <section class="card" id="bibtex">
    <h2 class="section-title">BibTeX</h2>
    <figure></figure>
    <div class="bibtex">
@article{golbari2025impMIA,
  title   = {ImpMIA: Leveraging Implicit Bias for Membership Inference under Realistic Scenarios},
  author  = {Golbari, Yuval and Wasserman, Navve and Vardi, Gal and Irani, Michal},
  journal = {arXiv preprint arXiv:2510.10625},
  year    = {2025}
}
    </div>
  </section>

  <section style="max-width:var(--max); margin:24px auto 40px; padding:0 16px; color:var(--muted); text-align:center;">
    © 2025 ImpMIA Authors.
  </section>

</body>
</html>
